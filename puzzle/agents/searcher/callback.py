import json
from ..base import (
    BaseAgentCallback, 
    NodeEventTiming, 
    OnChainStartContext,
    OnChainEndContext,
    OnToolStartContext,
    OnToolEndContext,
    OnToolErrorContext,
    OnLLMStartContext,
    OnLLMEndContext,
)
from .prompts import evaluate_current_status_output_parser, generate_answer_output_parser
from .states import SearchAgentState
from db import db_integration
from typing import cast, Optional


class DBIntegrationCallback(BaseAgentCallback):
    def __init__(self):
        super().__init__()
        
        self.current_retrieval_step_purpose: Optional[str] = None
        
        # ä¿å­˜å½“å‰ retrieval step purposeï¼Œæ–¹ä¾¿åŒ¹é…å¯¹åº”çš„ node
        @self.node_event(node_name="__start__", timing=NodeEventTiming.ON_CHAIN_START)
        def store_news_text_to_db(context: OnChainStartContext):
            inputs = cast(SearchAgentState, context["inputs"])
            self.current_retrieval_step_purpose = inputs.purpose
        
        @self.node_event(node_name="evaluate_current_status", timing=NodeEventTiming.ON_CHAIN_END)
        def store_search_evidences_to_db(context: OnChainEndContext):
            if not self.current_retrieval_step_purpose:
                raise ValueError("Current retrieval step purpose is not set.")
            
            outputs = context["outputs"]
            if not outputs.get("evidences"): # æ£€ç´¢è¿‡ç¨‹ä¸­å¯èƒ½æ²¡æœ‰æ£€ç´¢åˆ°æ–°è¯æ®
                return
            db_integration.store_search_evidences(self.current_retrieval_step_purpose, outputs["evidences"])
            
        @self.node_event(node_name="generate_answer", timing=NodeEventTiming.ON_CHAIN_END)
        def store_search_result_to_db(context: OnChainEndContext) -> None:
            if not self.current_retrieval_step_purpose:
                raise ValueError("Current retrieval step purpose is not set.")
            
            outputs = context["outputs"]
            db_integration.store_search_results(self.current_retrieval_step_purpose, outputs["result"])
    

class CLIModeCallback(BaseAgentCallback):
    """
    Search Agent CLI Mode å›è°ƒï¼Œä¸»è¦ç”¨äºåœ¨ terminal æ˜¾ç¤º LLM çš„æ¨ç†è¿‡ç¨‹
    """

    def __init__(self):
        super().__init__()
        
        self.step_count = 0  # æ€»æ­¥éª¤è®¡æ•°
        self.llm_call_count = 0  # LLMè°ƒç”¨è®¡æ•°
        self.start_time = None
        self.last_tokens = 0
        # ANSI é¢œè‰²ä»£ç 
        self.colors = {
            "blue": "\033[94m",
            "green": "\033[92m",
            "yellow": "\033[93m",
            "red": "\033[91m",
            "purple": "\033[95m",
            "cyan": "\033[96m",
            "bold": "\033[1m",
            "reset": "\033[0m",
        }
        
        self.handle_chain_end()
        self.handle_tools()
        self.print_llm_start_info()
        self.print_llm_results()

    def _print_colored(self, text, color="blue", bold=False):
        prefix = ""
        if bold:
            prefix += self.colors["bold"]

        if color in self.colors:
            prefix += self.colors[color]

        print(f"{prefix}{text}{self.colors['reset']}")

    def _format_json(self, data):
        if isinstance(data, str):
            try:
                parsed_data = json.loads(data)
                return json.dumps(parsed_data, indent=2, ensure_ascii=False)
            except:
                return data
        elif isinstance(data, (dict, list)):
            return json.dumps(data, indent=2, ensure_ascii=False)
        else:
            return str(data)
    
    def handle_chain_end(self):
        @self.node_event(timing=NodeEventTiming.ON_CHAIN_END)
        def track_token_usage(context: OnChainEndContext):
            outputs = context["outputs"]
            if "token_usage" in outputs:
                current_tokens = int(outputs["token_usage"])
                tokens_used = current_tokens - self.last_tokens

                # åªæœ‰å½“tokenæ¶ˆè€—æœ‰å˜åŒ–æ—¶æ‰æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                if tokens_used > 0:
                    self.last_tokens = current_tokens

                    self._print_colored(f"\nğŸ“Š Tokenæ¶ˆè€—ç»Ÿè®¡: ", "blue", True)
                    self._print_colored(f"   æœ¬æ¬¡æ¶ˆè€—: {tokens_used} tokens", "blue")
                    self._print_colored(f"   ç´¯è®¡æ¶ˆè€—: {current_tokens} tokens", "blue")
                    self._print_colored(f"{'-'*50}", "blue")
        
    def handle_tools(self):
        @self.node_event(timing=NodeEventTiming.ON_TOOL_START)
        def print_tool_start(context: OnToolStartContext):

            tool_name = context["serialized"].get("name", "Unknown Tool")
            self._print_colored(f"\nğŸ”¨ å¼€å§‹æ‰§è¡Œå·¥å…·: {tool_name}", "purple")
            self._print_colored(f"ğŸ“¥ è¾“å…¥: {context['input_str']}", "purple")

        @self.node_event(timing=NodeEventTiming.ON_TOOL_END)
        def print_tool_result(context: OnToolEndContext):
            output = context["output"]
            
            self._print_colored(f"\nğŸ“¤ å·¥å…·æ‰§è¡Œç»“æœ:", "green")
            
            # å¤„ç†ä¸åŒç±»å‹çš„è¾“å‡º
            try:
                # å¦‚æœæ˜¯å­—ç¬¦ä¸²ç±»å‹ï¼Œæ£€æŸ¥é•¿åº¦å¹¶å¯èƒ½æˆªæ–­
                if isinstance(output, str):
                    if len(output) > 500:
                        self._print_colored(f"{output[:497]}...", "green")
                    else:
                        self._print_colored(output, "green")
                else:
                    # å¤„ç†éå­—ç¬¦ä¸²ç±»å‹
                    self._print_colored(str(output), "green")
            except Exception as e:
                # æ•è·ä»»ä½•é”™è¯¯ï¼Œç¡®ä¿å›è°ƒä¸ä¼šä¸­æ–­ä¸»ç¨‹åº
                self._print_colored(f"è¾“å‡ºå¤„ç†é”™è¯¯: {str(e)}", "red")

        @self.node_event(timing=NodeEventTiming.ON_TOOL_ERROR)
        def print_tool_error(context: OnToolErrorContext):
            error = context["error"]
            
            self._print_colored(f"\nâŒ å·¥å…·æ‰§è¡Œé”™è¯¯:", "red", True)
            self._print_colored(f"{str(error)}", "red")
            self._print_colored(f"{'-'*50}", "red")

    def print_llm_start_info(self):
        @self.node_event(node_name="evaluate_current_status", timing=NodeEventTiming.ON_LLM_START)
        def print_evaluate_status_start(context: OnLLMStartContext):
            self.llm_call_count += 1
            model_name = context["serialized"]["name"]
            self._print_colored(
                f"\nğŸ§  LLM å¼€å§‹è¯„ä¼°å½“å‰çŠ¶æ€ (è°ƒç”¨ #{self.llm_call_count}, {model_name})",
                "purple",
                True,
            )
        
        @self.node_event(node_name="generate_answer", timing=NodeEventTiming.ON_LLM_START)
        def print_generate_answer_start(context: OnLLMStartContext):
            model_name = context["serialized"]["name"]
            self.llm_call_count += 1
            self._print_colored(
                f"\nğŸ§  LLM å¼€å§‹ç”Ÿæˆæ£€ç´¢ç»“è®º (è°ƒç”¨ #{self.llm_call_count}, {model_name})",
                "green",
                True,
            )
        
    def print_llm_results(self):
        @self.node_event(node_name="evaluate_current_status", timing=NodeEventTiming.ON_LLM_END)
        def print_status_evaluation_end(context: OnLLMEndContext):
            generated_text = context["response"].generations[0][0].text
            try:
                parsed_result = evaluate_current_status_output_parser.parse(generated_text)
                self._print_status_evaluation(parsed_result)
            except Exception as e:
                self._print_colored(f"è§£æçŠ¶æ€è¯„ä¼°å¤±è´¥: {str(e)}", "red")
                self._print_colored(generated_text, "cyan")
        
        @self.node_event(node_name="generate_answer", timing=NodeEventTiming.ON_LLM_END)
        def print_generate_answer_end(context: OnLLMEndContext):
            generated_text = context["response"].generations[0][0].text
            try:
                parsed_result = generate_answer_output_parser.parse(generated_text)
                self._print_search_result(parsed_result)
            except Exception as e:
                self._print_colored(f"è§£ææ ¸æŸ¥ç»“è®ºå¤±è´¥: {str(e)}", "red")
                self._print_colored(generated_text, "cyan")
        
    def _print_status_evaluation(self, status):
        """æ‰“å°çŠ¶æ€è¯„ä¼°ä¿¡æ¯"""
        # æ‰“å°è¯„ä¼°ç»“æœ
        self._print_colored("\nğŸ” è¯„ä¼°åæ€:", "yellow", True)
        
        # æ‰“å°è¯„ä¼°
        if hasattr(status, "evaluation") and status.evaluation:
            self._print_colored(f"ğŸ“Š è¯„ä¼°: {status.evaluation}", "yellow")
            
        # æ‰“å°ç¼ºå¤±ä¿¡æ¯
        if hasattr(status, "missing_information") and status.missing_information:
            self._print_colored(f"â“ ç¼ºå¤±ä¿¡æ¯: {status.missing_information}", "red", True)
        
        # æ‰“å°è®°å¿†
        if hasattr(status, "memory") and status.memory:
            self._print_colored(f"ğŸ§  è®°å¿†: {status.memory}", "yellow")
        
        # æ‰“å°ä¸‹ä¸€æ­¥
        if hasattr(status, "next_step") and status.next_step:
            self._print_colored(f"ğŸ‘£ ä¸‹ä¸€æ­¥: {status.next_step}", "yellow")
        
        # æ‰“å°åŠ¨ä½œ
        if hasattr(status, "action") and status.action:
            # å¤„ç†ä¸åŒç±»å‹çš„action
            if status.action == "answer":
                self._print_colored(f"ğŸ› ï¸ è¡ŒåŠ¨: ç”Ÿæˆå›ç­”", "yellow", True)
            elif isinstance(status.action, list):
                # å¤„ç†å·¥å…·è°ƒç”¨åˆ—è¡¨
                for i, tool_call in enumerate(status.action):
                    tool_name = tool_call.get("name", "æœªçŸ¥å·¥å…·") if isinstance(tool_call, dict) else str(tool_call)
                    self._print_colored(f"ğŸ› ï¸ è¡ŒåŠ¨ #{i+1}: {tool_name}", "yellow", True)
                    
                    # å¦‚æœæ˜¯å­—å…¸ä¸”æœ‰argså­—æ®µ
                    if isinstance(tool_call, dict) and "args" in tool_call:
                        args_str = json.dumps(tool_call["args"], ensure_ascii=False)
                        self._print_colored(f" {args_str}", "yellow")
            else:
                # å¤„ç†å…¶ä»–æƒ…å†µ
                self._print_colored(f"ğŸ› ï¸ è¡ŒåŠ¨: {str(status.action)}", "yellow", True)
        
        # æ‰“å°æ–°è¯æ®
        if hasattr(status, "new_evidence") and status.new_evidence:
            self._print_colored(f"ğŸ“‹ æ–°è¯æ®:", "green", True)
            for evidence in status.new_evidence:
                self._print_colored(f"  â€¢ {evidence.content}", "green")
                self._print_colored(f"  â€¢ {evidence.source}", "green")
                self._print_colored(f"  â€¢ {evidence.reasoning}", "green")
                self._print_colored(f"  â€¢ {evidence.relationship}", "green")
    
    def _print_search_result(self, result):
        """æ‰“å°æœç´¢ç»“æœä¿¡æ¯"""
        self._print_colored("\nğŸ æ ¸æŸ¥ç»“è®º:", "green", True)
        
        # æ‰“å°æ‘˜è¦
        if hasattr(result, "summary") and result.summary:
            self._print_colored(f"ğŸ“Š æ‘˜è¦: {result.summary}", "green")
        
        # æ‰“å°ç»“è®º
        if hasattr(result, "conclusion") and result.conclusion:
            self._print_colored(f"ğŸ ç»“è®º: {result.conclusion}", "green", True)
        
        # æ‰“å°æ¥æº
        if hasattr(result, "sources") and result.sources:
            self._print_colored(f"ğŸ“š æ¥æº:", "cyan", True)
            for source in result.sources:
                self._print_colored(f"  â€¢ {source}", "cyan")
        
        # æ‰“å°ç½®ä¿¡åº¦
        if hasattr(result, "confidence") and result.confidence:
            self._print_colored(f"â­ ç½®ä¿¡åº¦: {result.confidence}", "cyan", True)
